---
title: "Practical Machine Learning, Weight Lifting Data set"
author: "github.com/sylvest00"
date: "November 20, 2016"
output: html_document
---

#Objective
The objective of this project was to predict the class, representative of the efficacy and form during weight lifting, of data collected from sensors worn by individuals who performed various weightlifting exercises in a research setting. Sensors measured the acceleration, direction, and position of the weights that were lifted as well as important body parts of the lifter (e.g. arm, belt, hip) along three axis (x, y, and z).

Classes predicted were either A, B, C, D, or E.

```{r, message = FALSE, warning = FALSE, echo = FALSE}
# Clear workspace
rm(list = ls())
graphics.off()

# Load required library
library(knitr)      # knit to create a HTML, PDF w/ Tex, or Word file
library(ggplot2)    # plotting
library(rmarkdown)  # r markdown
library(caret)
library(dplyr)
library(corrplot)
library(cowplot)
require(GGally)     # Correlation matrix + figures
```

## Preparing the data
The data were loaded into the work space and data columns that contained dynamic information such information on movement (`accel`), position (`pitch`, `yaw`, `roll`), and direction (`gyros`, `magnet`) of the tracked objects were selected. All other information in the data set were either summary statistics or were specific to the subject who participated in the study. There were thus not included in the training data set.

The training data set was split with 75% used for training the model (`train1`) and the remaining 25% to test the model (`train2`). The variables in `train1` were checked for variation (variance and frequency counts) to ensure that they would be efficient predictors of the outcome variable `classe`. For this, I used `nearZeroVar`.

```{r, message = FALSE, warning = FALSE}
# Load data
dfTest <- read.csv("pml_testing.csv")
dfTrain <- read.csv("pml_training.csv")

# Subset for movement, position, and direction data
train_data <- select(dfTrain, starts_with('gyros_'), starts_with('accel_'), starts_with('magnet_'), starts_with('roll_'), starts_with('pitch_'), starts_with('yaw_'), matches('classe'))

test_data <- select(dfTest, starts_with('gyros_'), starts_with('accel_'), starts_with('magnet_'), starts_with('roll_'), starts_with('pitch_'), starts_with('yaw_'))

# Split the training data into a test and training set
set.seed(1)
trainIdx <- createDataPartition(train_data$classe, p = 0.75, list = FALSE)
train1 <- train_data[trainIdx,] # train the model
train2 <- train_data[-trainIdx,] # test the model

# Check for variables with low variance, will not contribute to model much
nsv <- nearZeroVar(train_data, saveMetrics = TRUE)
```
All variables have variances that are non-zero, so no changes were made to`train1`.

## Exploratory Analysis
Correlation matrices were created in order to quantitatively and visually examine what variables co-vary. The function `flattenCorrMatrix` found on [sthga.com](http://www.sthda.com/english/wiki/correlation-matrix-a-quick-start-guide-to-analyze-format-and-visualize-a-correlation-matrix-using-r-software) was used to transform the n x n correlation matrix into a ((n^2)/2) - (n/2) x 3 table where columns 1 and 2 are the names of the variables that were compared and column 3 contains the correlation values.

Below is the correlation matrix, the first 5 entries of the transformed correlation table, and plots of highly (positive and negative) correlated pairs of variables (abs(correlation) >= 0.5).
```{r, message = FALSE, warning = FALSE, echo = FALSE}
# ++++++++++++++++++++++++++++
# flattenCorrMatrix
# ++++++++++++++++++++++++++++
# cormat : matrix of the correlation coefficients
# pmat : matrix of the correlation p-values
# From http://www.sthda.com/english/wiki/correlation-matrix-a-quick-start-guide-to-analyze-format-and-visualize-a-correlation-matrix-using-r-software

flattenCorrMatrix <- function(cormat) {
  ut <- upper.tri(cormat)
  data.frame(
    row = rownames(cormat)[row(cormat)[ut]],
    column = rownames(cormat)[col(cormat)[ut]],
    cor  =(cormat)[ut]
    )
}
```

```{r, message = FALSE, warning = FALSE, echo = FALSE}
colNum <- length(colnames(train1))
# Correlation matrix for entire data frame
corrMatrix <- cor(train1[,1:colNum-1])

# Show correlation matrix, colored and with dots for each correlation
corrplot(corrMatrix, order = 'hclust')

# Flatten correlation amtrix
corrTable <- flattenCorrMatrix(corrMatrix)
idx <- which(abs(corrTable$cor) >= 0.5)
corrTable2 <- corrTable[idx,]
sortCorrTable <- sort(corrTable2$cor, decreasing = TRUE, index.return = TRUE)
```

<br>
Figure 1: Correlation matrix of `train1`
<br>
```{r, message = FALSE, warning = FALSE}
# Display first 5 of the tranformed table
head(corrTable2[sortCorrTable$ix,])
```

Table 1: First 5 correlation values greater than or equal to 0.5
<br>

```{r, message = FALSE, warning = FALSE, echo = FALSE}
p1 <- ggplot(train1, aes(accel_belt_z,roll_belt)) +
    geom_point(aes(colour = factor(classe))) 

p2 <- ggplot(train1, aes(accel_belt_y,roll_belt)) +
    geom_point(aes(colour = factor(classe)))

p3 <- ggplot(train1, aes(accel_belt_z,magnet_dumbbell_z)) +
    geom_point(aes(colour = factor(classe)))

plot_grid(p1,p2,p3, labels = c('A','B','C'))
```

<br>
Figure 2: Plots of highly correlated predictors. (a) Belt (z) Accelerate vs. Belt Roll, (b) Belt (y) Accelerate vs. Belt Roll, (c) Belt (z) Accelerate vs. Magnet (z) Dumbbell.

## Predictive Models
This is a classification problem since the goal is to predict the outcome variable, `classe`, which can only be A-E. After plotting a few relationships (Fig. 2), it is not clear if there are non-overlapping clusters in the data set. This rules out classification via clustering algorithms. For this project, I will try decision trees and random forest classification to predict the `classe` variable of the test data set.

### Decision Tree
To begin, I first trained the model and cross validated using 5 folds. I checked the performance of the model using `train2` and a confusion matrix.
```{r, message = FALSE, warning = FALSE}
set.seed(1)

# Decision tree with cross validation
mF1_tc <- trainControl(method="cv", number=5, verboseIter=F)
modelFit1 <- train(classe ~ ., data = train1, method = "rpart", trControl = mF1_tc)
confMatrix1 <- confusionMatrix(train2$classe, predict(modelFit1,train2[,1:dim(train2)[[2]]-1]))

# Display CM
confMatrix1$table
```
The accuracy of the decision tree is pretty poor (`r round(confMatrix1$overall[[1]],3)`).

### Random Forest
Next, I tried random forest classification. I cross validated using 5 folds and also checked the accuracy of the model via a confusion matrix. As noted by TA/ moderator [Lgreski](https://github.com/lgreski/datasciencectacontent/blob/master/markdown/pml-requiredModelAccuracy.md accuracy benchmark recommendations that will allow me to at least past the quiz), the accuracy must be around 0.99 in order to score well on the project's quiz.
```{r, message = FALSE, warning = FALSE}
# Randon forest with cross validation
modelFit2 <- train(classe ~ ., data = train1, method = "rf", trControl = mF1_tc)
confMatrix2 <- confusionMatrix(train2$classe, predict(modelFit2,train2[,1:dim(train2)[[2]]-1]))

# Display CM
confMatrix2$table
```
The accuracy from the random forest classifier is `r round(confMatrix2$overall[[1]],3)`. Since the accuracy is high, I will use random forest classification to make final predictions on the test set.

### Retrain and Predict Outcome
To finish, the model was retrained using the entire training data set and predictions were made from the test set.
```{r, message = FALSE, warning = FALSE}
# Retrain the model on everything
modelFit_final <- train(classe ~ ., data = train_data, method = "rf", trControl = mF1_tc)
modelPreds <- predict(modelFit_final,test_data)
```
The predictions are as follows: B, A, B, A, A, E, D, B, A, A, B, C, B, A, E, E, A, B, B, B.